{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57de2d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 23:36:29 WARN Utils: Your hostname, Ubos-iMac.local resolves to a loopback address: 127.0.0.1; using 192.168.100.11 instead (on interface en0)\n",
      "23/02/09 23:36:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/02/09 23:36:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Find path to PySpark.\n",
    "import findspark\n",
    "findspark.init(\"/Users/ugalugalu/spark-3.3.1-bin-hadoop3/\")\n",
    "import pyspark\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "#Create a spark context object\n",
    "sc = pyspark.SparkContext()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ff9ecfc",
   "metadata": {},
   "source": [
    "### 1.Data Importation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c17b909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ugalugalu/spark-3.3.1-bin-hadoop3/python/pyspark/sql/context.py:112: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create Sqlcontext Object\n",
    "\n",
    "sqlCtx = SQLContext(sc)\n",
    "\n",
    "#Read in the data using the SQL context object\n",
    "data = sqlCtx.read.csv('saf_stock.csv',header= True, inferSchema= True)\n",
    "data.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0119468",
   "metadata": {},
   "source": [
    "Observations:The Column names are Date,Open,High,Low,Close,Volume, and Adj Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99fedea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: timestamp (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Infering the schema from the data\n",
    "data.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae6320fb",
   "metadata": {},
   "source": [
    "Observations about the schema:All the six columns are of string columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2092fdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|               Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03 00:00:00|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04 00:00:00|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05 00:00:00|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06 00:00:00|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09 00:00:00|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+-------------------+------------------+---------+---------+------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Showing the first five columns\n",
    "data.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43c3ad0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Checking for Statistical Distribution\n",
    "data.describe().show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "60e1bd6c",
   "metadata": {},
   "source": [
    "### 2.Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "479329fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+-----+-----+-----+--------+---------+------------+\n",
      "|               Date| Open| High|  Low|Close|  Volume|Adj Close|          HV|\n",
      "+-------------------+-----+-----+-----+-----+--------+---------+------------+\n",
      "|2012-01-03 00:00:00|59.97|61.06|59.87|60.33|12668800|    52.62|0.0000048197|\n",
      "|2012-01-04 00:00:00|60.21|60.35|59.47|59.71| 9593300|    52.08|0.0000062908|\n",
      "|2012-01-05 00:00:00|59.35|59.62|58.37|59.42|12768200|    51.83|0.0000046694|\n",
      "|2012-01-06 00:00:00|59.42|59.45|58.87|59.00| 8069400|    51.46|0.0000073673|\n",
      "|2012-01-09 00:00:00|59.03|59.55|58.92|59.18| 6679300|    51.62|0.0000089156|\n",
      "+-------------------+-----+-----+-----+-----+--------+---------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import preparation modules\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import lit,when,col,expr,round\n",
    "\n",
    "# Create a new data frame and round off the columns to two decimal places while adding the new HV column\n",
    "\n",
    "data2=(\n",
    "data.withColumn('HV',expr(\"High/Volume\"))#Create the new column HV which is a ratio if High to Volume ratio of stocks traded\\\n",
    "    .withColumn('Open', F.format_number('Open', 2))# Round the Open Column to two decimal places\\\n",
    "    .withColumn('High', F.format_number('High', 2))# Round the high column to two decimal places\\\n",
    "    .withColumn('Low', F.format_number('Low', 2))# Round the Low column to two decimal places\\\n",
    "    .withColumn('Close', F.format_number('Close', 2))# Round the close column to two decimal places\\\n",
    "    .withColumn('Volume', round('Volume', 2))#round the volume column to two decimal places.Round function used in this case to solve comma issues\\\n",
    "    .withColumn('Adj Close', F.format_number('Adj Close', 2))# Round the close column to two decimal places\\\n",
    "    .withColumn('HV',F.format_number('HV', 10)))# Round the new HV column to 10 decimal places\n",
    " \n",
    "data2.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a4e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ugalugalu/spark-3.3.1-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Register a table in SQL\n",
    "table = data2.registerTempTable(\"SAF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d4c62f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['saf']\n"
     ]
    }
   ],
   "source": [
    "#Confirm that SAF has been registered\n",
    "tables = sqlCtx.tableNames()\n",
    "\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97362c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------------+\n",
      "|               Date|Peak_High_Price|\n",
      "+-------------------+---------------+\n",
      "|2015-01-13 00:00:00|          90.97|\n",
      "+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 1: What day had the peak high in price?\n",
    "q = \"SELECT \\\n",
    "         Date,max(High) AS Peak_High_Price \\\n",
    "     FROM SAF GROUP BY Date \\\n",
    "    ORDER BY Peak_High_Price DESC LIMIT 1 \"\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e4a8d529",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "13th January 2015 had Peak High Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66add223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|             MEAN|\n",
      "+-----------------+\n",
      "|72.38844992050863|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Question 2: What is the mean of the close month?\n",
    "q = \"\\\n",
    "SELECT\\\n",
    "    MEAN(Close) AS MEAN\\\n",
    "        FROM SAF\"\n",
    "\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf6399ce",
   "metadata": {},
   "source": [
    "The mean of the close month was 72.38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a00fca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|Min_Volume|Max_Volume|\n",
      "+----------+----------+\n",
      "|   2094900|  80898100|\n",
      "+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the max and min of the volume column\n",
    "\n",
    "q = \"SELECT\\\n",
    "     MIN(Volume) Min_Volume,MAX(Volume) Max_Volume\\\n",
    "         FROM SAF\\\n",
    " \"\n",
    "\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a43b364",
   "metadata": {},
   "source": [
    "The minimum Volume was 2094900 while Maximum value was 80898100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f5b7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(Date)|\n",
      "+-----------+\n",
      "|        116|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many days was the close lower than 60 dollars?\n",
    "q = \"SELECT\\\n",
    "    COUNT(Date)\\\n",
    "    FROM SAF\\\n",
    "    WHERE Close <= 60\\\n",
    "    \"\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "53916ccd",
   "metadata": {},
   "source": [
    "116 days had a close lower than 60 dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f70050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|Percentage_Greater_Than_80|\n",
      "+--------------------------+\n",
      "|                      9.14|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What percentage of the time was the High greater than 80 Dollars\n",
    "# Total column entries were computed earlier. An improved querry of this is to use Common Table Expressions for this querry\n",
    "\n",
    "q = \"SELECT\\\n",
    "     ROUND((COUNT(High)/1258*100),2) Percentage_Greater_Than_80\\\n",
    "         FROM SAF\\\n",
    "         WHERE High >= 80\\\n",
    "            \"\n",
    "\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41f07dc2",
   "metadata": {},
   "source": [
    "9.14% had time greater than 80 Dollars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ac84d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|Pearson_Correlation|\n",
      "+-------------------+\n",
      "|              -0.34|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the Pearson correlation between High and Volume\n",
    "\n",
    "q = \"SELECT ROUND(corr(High,Volume),2) Pearson_Correlation\\\n",
    "          FROM SAF\"\n",
    "\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ee0e52c",
   "metadata": {},
   "source": [
    "The Pearson Correlation Between High and Volume is -0.338, meaning that they are negatively correlated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a48f4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+\n",
      "|Year|Max_High|\n",
      "+----+--------+\n",
      "|2015|   90.97|\n",
      "|2014|   88.09|\n",
      "|2013|   81.37|\n",
      "|2012|   77.60|\n",
      "|2016|   75.19|\n",
      "+----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What is the Max High per Year\n",
    "\n",
    "q = \"SELECT\\\n",
    "     EXTRACT(YEAR FROM Date) Year,\\\n",
    "     MAX(High) Max_High\\\n",
    "     FROM SAF\\\n",
    "     GROUP BY Year\\\n",
    "     ORDER BY Max_High DESC\"\n",
    "sqlCtx.sql(q).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7e4e211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|Month|Avg_Close|\n",
      "+-----+---------+\n",
      "|    1|    71.45|\n",
      "|    2|    71.31|\n",
      "|    3|    71.78|\n",
      "|    4|    72.97|\n",
      "|    5|    72.31|\n",
      "|    6|     72.5|\n",
      "|    7|    74.44|\n",
      "|    8|    73.03|\n",
      "|    9|    72.18|\n",
      "|   10|    71.58|\n",
      "|   11|    72.11|\n",
      "|   12|    72.85|\n",
      "+-----+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#What is the average Close for each Calendar Month?\n",
    "q = \"SELECT\\\n",
    "    EXTRACT(MONTH FROM Date) Month,\\\n",
    "    ROUND(AVG(Close),2) Avg_Close\\\n",
    "    FROM SAF\\\n",
    "    GROUP BY Month\\\n",
    "    ORDER BY Month ASC\"\n",
    "\n",
    "sqlCtx.sql(q).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "caa13fab9fa604ad9ca3778e69ccc4111fad5d5c0dd4e3e0f7a37964d2ffe6e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
